{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, LSTM, Flatten, Dense, BatchNormalization\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import bootstrap\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create confusion Matrix\n",
    "def confusionMatrix(model, testX, testY):\n",
    "    pred = model.predict(testX)\n",
    "    predy = []\n",
    "    for i in range(0,len(pred)):\n",
    "        if pred[i] >= .5:\n",
    "            predy.append(1)\n",
    "        else:\n",
    "            predy.append(0)\n",
    "        \n",
    "    print(confusion_matrix(testY,predy))\n",
    "    \n",
    "#Calculates our model metrics\n",
    "def modelMetrics(testX, testY, model):\n",
    "    y_scores = model.predict(testX)\n",
    "    precision, recall, thresholds = precision_recall_curve(testY, y_scores)\n",
    "    rec80 = np.max(recall[precision >= .8])\n",
    "    print(\"Recall at 80% Precision: \" +str(rec80))\n",
    "    aucPR = auc(recall, precision)\n",
    "    print(\"PR-AUC: \" + str(aucPR))\n",
    "    \n",
    "    return rec80, aucPR, \n",
    "\n",
    "#plots a PR curve\n",
    "def PRplot(testX, testY, model):\n",
    "    y_scores = model.predict(testX)\n",
    "    precision, recall, thresholds = precision_recall_curve(testY, y_scores)\n",
    "    plt.plot(recall, precision)\n",
    "    plt.title(\"PR curve\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data): \n",
    "    for i in data.columns:\n",
    "        data[i] = (data[i] - np.mean(data[i]))/np.std(data[i])\n",
    "    return np.nan_to_num(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newModel(numConvFilters = 242, dropout = .6, numDenseNodes = 190):\n",
    "    #Create new sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    #Add 1D Convolutional layers\n",
    "    model.add((Conv1D(filters=32, kernel_size=3, activation='relu')))\n",
    "    model.add((Conv1D(filters=numConvFilters, kernel_size=3, activation='relu')))\n",
    "    #Add Max Pooling layer\n",
    "    model.add((MaxPooling1D(pool_size=2)))\n",
    "    #Apply dropout\n",
    "    model.add(Dropout(dropout))\n",
    "    #Flatten model\n",
    "    model.add(Flatten())\n",
    "    #Add fully connected dense layer\n",
    "    model.add(Dense(numDenseNodes, activation='sigmoid'))\n",
    "    #Add output node\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    #Define optimizer\n",
    "    adam = tf.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "    #Compile model\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC(curve='PR'),   \n",
    "                                                                       tf.keras.metrics.RecallAtPrecision(0.8)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate positive and negative samples\n",
    "trainFull = pd.read_csv(\"PreprocessedData/trainFull.csv\")\n",
    "testFull = pd.read_csv(\"PreprocessedData/testFull.csv\")\n",
    "\n",
    "trainIndex = np.arange(0,len(trainFull))\n",
    "testIndex = np.arange(0,len(testFull))\n",
    "\n",
    "trainResample = np.random.choice(trainIndex, size = len(trainFull))\n",
    "testResample = np.random.choice(testIndex, size = len(testFull))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainResampleFull = trainFull.iloc[trainResample]\n",
    "testResampleFull = testFull.iloc[testResample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce features and extract labels\n",
    "trainX = trainResampleFull.iloc[:,:-2]\n",
    "trainY = trainResampleFull.iloc[:,-1]\n",
    "testX = testResampleFull.iloc[:,:-2]\n",
    "testY = testResampleFull.iloc[:,-1]\n",
    "\n",
    "trainX = normalize(trainX)\n",
    "testX = normalize(testX)\n",
    "\n",
    "#Reshape data to 3D for CNN\n",
    "\n",
    "trainX = trainX[..., None]\n",
    "trainY = trainY.to_numpy()[..., None]\n",
    "testX = testX[..., None]\n",
    "testY = testY.to_numpy()[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "758/758 [==============================] - 25s 31ms/step - loss: 0.5913 - auc_11: 0.7453 - recall_at_precision_11: 0.3189 - val_loss: 0.5419 - val_auc_11: 0.8162 - val_recall_at_precision_11: 0.6138\n",
      "Epoch 2/50\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.5397 - auc_11: 0.8049 - recall_at_precision_11: 0.5265"
     ]
    }
   ],
   "source": [
    "model= newModel()\n",
    "history = model.fit(trainX, trainY, validation_data = (testX, testY), epochs = 50, batch_size=20, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMetrics(testX, testY, model)\n",
    "confusionMatrix(model, testX, testY)\n",
    "PRplot(testX, testY, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keys = list(history.history.keys())\n",
    "plt.figure(figsize = (16,4))\n",
    "epoch = np.arange(1,31,1)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(epoch, history.history[keys[0]], label = \"Training\")\n",
    "plt.plot(epoch, history.history[keys[3]], label = \"Validation\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(epoch, history.history[keys[1]], label = \"Training\")\n",
    "plt.plot(epoch, history.history[keys[4]], label = \"Validation\")\n",
    "plt.title(\"Recall @ 80% Precision\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(epoch, history.history[keys[2]], label = \"Training\")\n",
    "plt.plot(epoch, history.history[keys[5]], label = \"Validation\")\n",
    "plt.title(\"PR AUC\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFull = pd.read_csv(\"PreprocessedData/trainFull.csv\")\n",
    "testFull = pd.read_csv(\"PreprocessedData/testFull.csv\")\n",
    "\n",
    "trainX = trainFull.iloc[:,:-2]\n",
    "trainY = trainFull.iloc[:,-1]\n",
    "testX = testFull.iloc[:,:-2]\n",
    "testY = testFull.iloc[:,-1]\n",
    "\n",
    "trainX = normalize(trainX)\n",
    "testX = normalize(testX)\n",
    "\n",
    "trainX = trainX[..., None]\n",
    "trainY = trainY.to_numpy()[..., None]\n",
    "testX = testX[..., None]\n",
    "testY = testY.to_numpy()[..., None]\n",
    "\n",
    "X = np.concatenate([trainX, testX])\n",
    "Y = np.concatenate([trainY, testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fr/03zv9zcj7j146mrr4jsb58kw0000gn/T/ipykernel_91973/2831822509.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfold_no\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "scores = []\n",
    "\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(X, Y):\n",
    "    model = newModel()\n",
    "    history = model.fit(X[train], Y[train], epochs = 15, batch_size=batch, verbose = 0)\n",
    "    scores.append(model.evaluate(X[test], Y[test], verbose=0))\n",
    "    print(f'fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%; {model.metrics_names[2]} of {scores[2]*100}%')\n",
    "    fold_no = fold_no + 1\n",
    "    confusionMatrix(model, X[test], Y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
