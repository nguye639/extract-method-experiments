{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, LSTM, Flatten, Dense, BatchNormalization\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import bootstrap\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create confusion Matrix\n",
    "def confusionMatrix(model, testX, testY):\n",
    "    pred = model.predict(testX)\n",
    "    predy = []\n",
    "    for i in range(0,len(pred)):\n",
    "        if pred[i] >= .5:\n",
    "            predy.append(1)\n",
    "        else:\n",
    "            predy.append(0)\n",
    "        \n",
    "    print(confusion_matrix(testY,predy))\n",
    "    \n",
    "#Calculates our model metrics\n",
    "def modelMetrics(testX, testY, model):\n",
    "    y_scores = model.predict(testX)\n",
    "    precision, recall, thresholds = precision_recall_curve(testY, y_scores)\n",
    "    rec80 = np.max(recall[precision >= .8])\n",
    "    print(\"Recall at 80% Precision: \" +str(rec80))\n",
    "    aucPR = auc(recall, precision)\n",
    "    print(\"PR-AUC: \" + str(aucPR))\n",
    "    \n",
    "    return rec80, aucPR, \n",
    "\n",
    "#plots a PR curve\n",
    "def PRplot(testX, testY, model):\n",
    "    y_scores = model.predict(testX)\n",
    "    precision, recall, thresholds = precision_recall_curve(testY, y_scores)\n",
    "    plt.plot(recall, precision)\n",
    "    plt.title(\"PR curve\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data): \n",
    "    for i in data.columns:\n",
    "        data[i] = (data[i] - np.mean(data[i]))/np.std(data[i])\n",
    "    return np.nan_to_num(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newModel(numConvFilters = 242, dropout = .215, numDenseNodes = 190):\n",
    "    #Create new sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    #Add 1D Convolutional layers\n",
    "    model.add((Conv1D(filters=32, kernel_size=3, activation='relu')))\n",
    "    model.add((Conv1D(filters=numConvFilters, kernel_size=3, activation='relu')))\n",
    "    #Add Max Pooling layer\n",
    "    model.add((MaxPooling1D(pool_size=2)))\n",
    "    #Apply dropout\n",
    "    model.add(Dropout(dropout))\n",
    "    #Flatten model\n",
    "    model.add(Flatten())\n",
    "    #Add fully connected dense layer\n",
    "    model.add(Dense(numDenseNodes, activation='sigmoid'))\n",
    "    #Add output node\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    #Define optimizer\n",
    "    adam = tf.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "    #Compile model\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC(curve='PR'),   \n",
    "                                                                       tf.keras.metrics.RecallAtPrecision(0.8)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1490  422]\n",
      " [ 333 1545]]\n",
      "Recall at 80% Precision: 0.7976570820021299\n",
      "PR-AUC: 0.8880738927769967\n",
      "[[1467  451]\n",
      " [ 330 1542]]\n",
      "Recall at 80% Precision: 0.7932692307692307\n",
      "PR-AUC: 0.8806311106547259\n",
      "[[1573  315]\n",
      " [ 469 1433]]\n",
      "Recall at 80% Precision: 0.7802313354363828\n",
      "PR-AUC: 0.884320557462374\n",
      "[[1626  282]\n",
      " [ 526 1356]]\n",
      "Recall at 80% Precision: 0.7821466524973433\n",
      "PR-AUC: 0.8869215324748826\n",
      "[[1600  315]\n",
      " [ 369 1506]]\n",
      "Recall at 80% Precision: 0.8421333333333333\n",
      "PR-AUC: 0.896757971350418\n",
      "[[1527  357]\n",
      " [ 385 1521]]\n",
      "Recall at 80% Precision: 0.8174186778593914\n",
      "PR-AUC: 0.8859854642298088\n",
      "[[1492  390]\n",
      " [ 348 1560]]\n",
      "Recall at 80% Precision: 0.8218029350104822\n",
      "PR-AUC: 0.8972468558600044\n",
      "[[1495  425]\n",
      " [ 343 1527]]\n",
      "Recall at 80% Precision: 0.7807486631016043\n",
      "PR-AUC: 0.8883010850364794\n",
      "[[1673  276]\n",
      " [ 484 1357]]\n",
      "Recall at 80% Precision: 0.8126018468223791\n",
      "PR-AUC: 0.8905118710400105\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(0,10):\n",
    "    #Concatenate positive and negative samples\n",
    "    trainFull = pd.read_csv(\"PreprocessedData/trainFull.csv\")\n",
    "    testFull = pd.read_csv(\"PreprocessedData/testFull.csv\")\n",
    "\n",
    "    trainIndex = np.arange(0,len(trainFull))\n",
    "    testIndex = np.arange(0,len(testFull))\n",
    "\n",
    "    trainResample = np.random.choice(trainIndex, size = len(trainFull))\n",
    "    testResample = np.random.choice(testIndex, size = len(testFull))\n",
    "\n",
    "    trainResampleFull = trainFull.iloc[trainResample]\n",
    "    testResampleFull = testFull.iloc[testResample]\n",
    "\n",
    "    #Reduce features and extract labels\n",
    "    trainX = trainResampleFull.iloc[:,:-2]\n",
    "    trainY = trainResampleFull.iloc[:,-1]\n",
    "    testX = testResampleFull.iloc[:,:-2]\n",
    "    testY = testResampleFull.iloc[:,-1]\n",
    "\n",
    "    trainX = normalize(trainX)\n",
    "    testX = normalize(testX)\n",
    "\n",
    "    #Reshape data to 3D for CNN\n",
    "\n",
    "    trainX = trainX[..., None]\n",
    "    trainY = trainY.to_numpy()[..., None]\n",
    "    testX = testX[..., None]\n",
    "    testY = testY.to_numpy()[..., None]\n",
    "    steps = 15\n",
    "    model= newModel()\n",
    "    history = model.fit(trainX, trainY, validation_data = (testX, testY), epochs = steps, batch_size=20, verbose = 0)\n",
    "    confusionMatrix(model, testX, testY)\n",
    "    modelMetrics(testX, testY, model)\n",
    "    scores.append(model.evaluate(testX, testY, verbose=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose = np.array(scores).T\n",
    "\n",
    "fold = np.arange(0,10)\n",
    "\n",
    "plt.figure(figsize = (16,4))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(fold,transpose[0])\n",
    "plt.plot(fold, np.full(10,np.mean(tranpose[0])))\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Sample\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(fold,transpose[1])\n",
    "plt.plot(fold, np.full(10,np.mean(tranpose[1])))\n",
    "plt.title(\"Recall @ 80% Precision\")\n",
    "plt.xlabel(\"Sample\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(fold,transpose[2])\n",
    "plt.plot(fold, np.full(10,np.mean(tranpose[2])))\n",
    "plt.title(\"PR-AUC\")\n",
    "plt.xlabel(\"Sample\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keys = list(history.history.keys())\n",
    "plt.figure(figsize = (16,4))\n",
    "epoch = np.arange(0,steps,1)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(epoch, history.history[keys[0]], label = \"Training\")\n",
    "plt.plot(epoch, history.history[keys[3]], label = \"Validation\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(epoch, history.history[keys[1]], label = \"Training\")\n",
    "plt.plot(epoch, history.history[keys[4]], label = \"Validation\")\n",
    "plt.title(\"Recall @ 80% Precision\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(epoch, history.history[keys[2]], label = \"Training\")\n",
    "plt.plot(epoch, history.history[keys[5]], label = \"Validation\")\n",
    "plt.title(\"PR AUC\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFull = pd.read_csv(\"PreprocessedData/trainFull.csv\")\n",
    "testFull = pd.read_csv(\"PreprocessedData/testFull.csv\")\n",
    "\n",
    "trainX = trainFull.iloc[:,:-2]\n",
    "trainY = trainFull.iloc[:,-1]\n",
    "testX = testFull.iloc[:,:-2]\n",
    "testY = testFull.iloc[:,-1]\n",
    "\n",
    "trainX = normalize(trainX)\n",
    "testX = normalize(testX)\n",
    "\n",
    "trainX = trainX[..., None]\n",
    "trainY = trainY.to_numpy()[..., None]\n",
    "testX = testX[..., None]\n",
    "testY = testY.to_numpy()[..., None]\n",
    "\n",
    "X = np.concatenate([trainX, testX])\n",
    "Y = np.concatenate([trainY, testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "scores = []\n",
    "\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(X, Y):\n",
    "    model = newModel()\n",
    "    history = model.fit(X[train], Y[train], epochs = 15, verbose = 0)\n",
    "    scores.append(model.evaluate(X[test], Y[test], verbose=0))\n",
    "    #print(f'fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%; {model.metrics_names[2]} of {scores[2]*100}%')\n",
    "    fold_no = fold_no + 1\n",
    "    confusionMatrix(model, X[test], Y[test])\n",
    "    modelMetrics(X[test], Y[test], model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose = np.array(scores).T\n",
    "\n",
    "fold = np.arange(0,10)\n",
    "\n",
    "plt.figure(figsize = (16,4))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(fold,transpose[0])\n",
    "plt.plot(fold, np.full(10,np.mean(tranpose[0])))\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Fold\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(fold,transpose[1])\n",
    "plt.plot(fold, np.full(10,np.mean(tranpose[1])))\n",
    "plt.title(\"Recall @ 80% Precision\")\n",
    "plt.xlabel(\"Fold\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(fold,transpose[2])\n",
    "plt.plot(fold, np.full(10,np.mean(tranpose[2])))\n",
    "plt.title(\"PR-AUC\")\n",
    "plt.xlabel(\"Fold\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
